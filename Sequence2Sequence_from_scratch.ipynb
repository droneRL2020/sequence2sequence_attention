{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.ops.rnn_cell import LSTMCell, LSTMStateTuple\n",
    "import helpers\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "#LSTMStateTuple(c,h)에서 c는 hidden state h는 output\n",
    "\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lstm_size_encoder = 128\n",
    "lstm_size_decoder = 256\n",
    "vocab_size = 679 #띄어쓰기도 하나의 word야?\n",
    "embed_size = 256# Document Vector로 Input된 총 문장수고 각 Vocab이 몇번 나왔는지 표기(?)\n",
    "#max_length = 5 \n",
    "\n",
    "\n",
    "#batch_size = 32\n",
    "encoder_cell = LSTMCell(lstm_size_encoder)\n",
    "decoder_cell = LSTMCell(lstm_size_decoder)\n",
    "GO = 0\n",
    "PAD = 0\n",
    "EOS = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings: Used int type embedding lookup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A revised edition of the rules of procedure has been issued under the symbol A/520/Rev.17.\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"en_fr\"\n",
    "input_file_en = os.path.join(data_dir, \"A_62_952_ADD1_en.snt\")\n",
    "lines_en = []\n",
    "with open(input_file_en, \"r\", encoding=\"utf-8\") as f_en:\n",
    "    for line in f_en.readlines():\n",
    "        line = line.replace('\\n','')\n",
    "        if not line == '':\n",
    "            lines_en.append(line)\n",
    "        \n",
    "print(lines_en[-2])\n",
    "#print((\"Text loaded from '%s'\") % (input_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Une version révisée du Règlement intérieur a été publiée sous la cote A/520/Rev.17.\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"en_fr\"\n",
    "#save_dir = \"eng_fre_dataset/multiUN.en/un/text/en-fr/2009\"\n",
    "input_file_fr = os.path.join(data_dir, \"A_62_952_ADD1_fr.snt\")\n",
    "lines_fr = []\n",
    "with open(input_file_fr, \"r\", encoding=\"utf-8\") as f_fr:\n",
    "    for line in f_fr.readlines():\n",
    "        line = line.replace('\\n','')\n",
    "        if not line == '':\n",
    "            lines_fr.append(line)\n",
    "        \n",
    "print(lines_fr[-2])\n",
    "#print((\"Text loaded from '%s'\") % (input_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(67, 67)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lines_en), len(lines_fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_data = []\n",
    "for i in range(len(lines_en)):\n",
    "    word_data.append((lines_en[i],lines_fr[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Sixty-second session', 'Soixante-deuxième session'),\n",
       " ('Agenda item 121', \"Point 121 de l'ordre du jour\"),\n",
       " ('Revitalization of the work of the General Assembly',\n",
       "  \"Revitalisation des travaux de l'Assemblée générale\"),\n",
       " ('Report of the Ad Hoc Working Group on the Revitalization of the General Assembly',\n",
       "  \"Rapport du Groupe de travail spécial sur la revitalisation de l'Assemblée générale\"),\n",
       " ('Addendum', 'Additif')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# word_data = [\n",
    "#     ('bye world good', 'thank you word'),\n",
    "#     ('sam gyup sal', 'ha ha'),\n",
    "#     ('bye world hi hi hi', 'Goodyhi')\n",
    "# ] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = [x for x, y in word_data]\n",
    "y = [y for x, y in word_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_list = []\n",
    "for i in range(len(x)):\n",
    "    x_text = x[i].split()\n",
    "    x_list.append(x_text)\n",
    "for i in range(1, len(x_list)):\n",
    "    x_list[i] = set(x_list[i-1]).union(set(x_list[i]))\n",
    "    x_words_set = x_list[len(x_list)-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_list = []\n",
    "for i in range(len(y)):\n",
    "    y_text = y[i].split()\n",
    "    y_list.append(y_text)\n",
    "for i in range(1, len(y_list)):\n",
    "    y_list[i] = set(y_list[i-1]).union(set(y_list[i]))\n",
    "    y_words_set = y_list[len(y_list)-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word2numX = dict(zip(x_words_set, range(len(x_words_set))))\n",
    "word2numY = dict(zip(y_words_set, range(len(y_words_set))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num2wordX = dict(zip(word2numX.values(), word2numX.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# max_len 뽑음\n",
    "numWordsList = []\n",
    "for word in x:\n",
    "    Words = word.split(' ')\n",
    "    num = len(Words)\n",
    "    numWordsList.append(num) \n",
    "max_len = max(numWordsList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "step1_X = [\n",
    "    word.split() for word in x\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "second_list = []\n",
    "for i in range(len(step1_X)):\n",
    "    first_list = []\n",
    "    for j in range(len(step1_X[i])):\n",
    "        k = word2numX[step1_X[i][j]]\n",
    "        first_list.append(k)\n",
    "        padded_list = first_list\n",
    "    second_list.append(padded_list)\n",
    "x = second_list\n",
    "x = np.array(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num2wordY = dict(zip(word2numY.values(), word2numY.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "step1_Y = [\n",
    "    word.split() for word in y\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "second_list = []\n",
    "for i in range(len(step1_Y)):\n",
    "    first_list = []\n",
    "    for j in range(len(step1_Y[i])):\n",
    "        k = word2numY[step1_Y[i][j]]\n",
    "        first_list.append(k)\n",
    "        padded_list = first_list\n",
    "    second_list.append(padded_list)\n",
    "y = second_list\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "679\n",
      "720\n"
     ]
    }
   ],
   "source": [
    "print(len(word2numX))\n",
    "print(len(word2numY))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'avoid', 1: 'indicate', 2: 'thereby', 3: 'Sixty-second', 4: 'obstacles', 5: 'revitalization).', 6: 'help', 7: 'States', 8: 'committees', 9: 'States,', 10: 'Nations', 11: 'has', 12: 'reorganized', 13: '46', 14: 'records', 15: 'Assembly.', 16: 'undertakes', 17: 'A/520/Rev.17.', 18: 'there', 19: 'carries', 20: 'to', 21: 'climate', 22: 'UNESCO', 23: 'opportunity', 24: 'languages,', 25: 'thematic', 26: 'provision', 27: 'Permanent', 28: \"Department's\", 29: 'photographers', 30: 'instruments', 31: 'plus', 32: 'Centre', 33: 'a', 34: 'indexes', 35: 'order', 36: 'all', 37: 'communications', 38: 'Management', 39: 'address', 40: 'areas', 41: 'would', 42: 'videoconferences', 43: 'Yearbook', 44: 'posted', 45: 'summaries', 46: 'mandates', 47: 'translation', 48: 'photographs', 49: 'may', 50: 'plenary,', 51: 'Rights', 52: 'Radio', 53: 'agenda,', 54: 'Conference,', 55: 'alerts', 56: 'necessary.', 57: 'group,', 58: 'implementation', 59: 'this', 60: 'etc.).', 61: 'list', 62: 'work', 63: 'representatives', 64: 'rights,', 65: 'similarly', 66: 'articles', 67: 'local', 68: 'Agenda', 69: 'decisions', 70: 'regions.', 71: '•', 72: 'body', 73: 'recommended', 74: 'official', 75: 'consultations', 76: 'include', 77: 'actions', 78: 'relevant', 79: 'learn', 80: 'site', 81: 'from', 82: '1981;', 83: 'been', 84: 'organizations', 85: 'educational', 86: 'revitalization.', 87: 'which', 88: 'issues', 89: 'evidence', 90: '(resolution', 91: 'process', 92: 'refer', 93: 'group', 94: 'Documentation', 95: 'deliberative', 96: 'Cluster', 97: 'improve', 98: 'French', 99: 'over', 100: 'basis.', 101: 'receipt', 102: 'At', 103: 'Assembly', 104: 'Activities', 105: 'extent', 106: 'Millennium', 107: 'etc.)', 108: 'Students', 109: 'introduction', 110: 'briefing', 111: 'speakers', 112: 'individual', 113: 'tour', 114: 'meetings', 115: 'entities', 116: '61/292.', 117: 'easy', 118: 'concern', 119: '60”,', 120: 'status', 121: 'languages),', 122: 'Hammarskjöld', 123: 'Guide', 124: 'easier', 125: '“Reaffirming', 126: 'presents', 127: 'contains', 128: 'half', 129: 'Human', 130: 'Main', 131: 'present', 132: 'recent', 133: 'identify', 134: 'Development.', 135: 'Services', 136: 'documents,', 137: 'found.', 138: 'concrete', 139: 'should', 140: 'archived', 141: 'entity', 142: 'areas.', 143: 'releases', 144: 'Government', 145: 'about', 146: 'versions', 147: 'public', 148: 'an', 149: 'further', 150: 'documentation.', 151: 'General', 152: 'teachers', 153: 'cover', 154: 'does', 155: 'major', 156: 'purpose', 157: 'offices', 158: 'meeting', 159: 'formulated', 160: 'In', 161: 'languages;', 162: 'targeted', 163: 'practical', 164: 'actual', 165: 'change,', 166: '61/292', 167: 'database', 168: 'United', 169: 'of', 170: 'any', 171: 'part', 172: 'on', 173: 'maintaining', 174: 'topics', 175: 'facilitate', 176: 'assessment', 177: 'pursuant', 178: \"Assembly's\", 179: 'additional', 180: 'following', 181: 'facilitation', 182: '45,000', 183: 'covered', 184: 'raise', 185: 'DPI/NGO', 186: 'syndicators', 187: 'methods,', 188: 'Chronicle', 189: \"Centre's\", 190: 'debate', 191: 'comments', 192: 'progress.', 193: 'emanating', 194: 'security,', 195: 'repeated', 196: 'revised', 197: 'expert.', 198: 'when', 199: 'audiences', 200: 'area', 201: 'conventions,', 202: 'still', 203: 'example,', 204: 'timely', 205: 'members', 206: 'reaching', 207: 'several', 208: 'subdivided', 209: 'retrieve', 210: 'during', 211: 'implementation.', 212: 'longer', 213: 'website', 214: 'promptly', 215: 'identifying', 216: 'via', 217: 'initiative,', 218: 'use', 219: 'prepare', 220: 'Each', 221: 'most', 222: 'outreach;', 223: 'international', 224: 'assistance', 225: 'Meetings', 226: '54,000', 227: 'make', 228: 'session;', 229: 'where', 230: 'special', 231: 'conducts', 232: 'coaching', 233: 'the', 234: 'Department', 235: '121', 236: 'other', 237: 'programme', 238: 'Personal', 239: 'organization', 240: 'high-resolution', 241: 'training', 242: '(1946', 243: 'sixty-first', 244: 'system.', 245: 'anniversary', 246: 'New', 247: 'obtained', 248: 'sixty-second', 249: 'Hoc', 250: 'Goals,', 251: 'The', 252: 'large', 253: 'analysing', 254: 'record', 255: 'held', 256: 'media,', 257: 'better', 258: 'Committees,', 259: 'omitted:', 260: 'session.', 261: 'dissemination', 262: 'useful,', 263: 'terms,', 264: 'fed', 265: 'year', 266: 'meeting,', 267: 'intention', 268: 'was', 269: 'backgrounders', 270: 'overtaken', 271: 'distributed', 272: 'II:', 273: 'interview', 274: 'Assembly,', 275: 'effectiveness', 276: '122nd', 277: 'webcasts,', 278: 'access', 279: '63', 280: 'I:', 281: 'principles', 282: 'types', 283: 'activities', 284: 'promote', 285: 'thus', 286: 'human', 287: 'inventory', 288: 'delegates', 289: 'Provisions', 290: 'within', 291: 'under', 292: 'offices;', 293: 'pertaining', 294: 'organize', 295: 'responsible', 296: 'if', 297: 'can', 298: 'delivery.', 299: 'visits', 300: 'high-level', 301: 'are', 302: 'had', 303: 'clarification', 304: 'item', 305: 'number.', 306: 'authority', 307: 'each', 308: 'material', 309: 'agenda.', 310: 'procedure', 311: 'annexes', 312: '2008.', 313: 'theme', 314: 'clusters', 315: 'requested', 316: 'importance', 317: 'on-site', 318: 'About', 319: 'and', 320: 'first', 321: 'result-oriented.', 322: 'realized', 323: 'Library', 324: 'frequently', 325: 'resolution.', 326: 'proceedings', 327: 'York;', 328: 'general', 329: 'English', 330: 'reaffirming', 331: 'Information', 332: 'generated', 333: 'great', 334: 'various', 335: 'feature', 336: 'Secretary-General', 337: 'divided', 338: 'mandated.', 339: 'view,', 340: 'Available', 341: 'coverage', 342: 'tour,', 343: 'onwards),', 344: 'produced', 345: 'To', 346: 'Paris', 347: 'world,', 348: 'include:', 349: 'main', 350: 'scope,', 351: 'after', 352: 'resolutions', 353: 'draft', 354: 'focuses', 355: 'effect.', 356: 'given', 357: 'back', 358: 'understandable', 359: 'we', 360: 'people', 361: 'only', 362: 'annual', 363: 'needed', 364: 'visitors', 365: 'every', 366: 'Member', 367: 'among', 368: 'news', 369: 'service.', 370: 'media', 371: 'events,', 372: 'later', 373: 'libraries', 374: 'well', 375: 'Co-Chairs,', 376: 'than', 377: 'included', 378: 'chart', 379: 'specific', 380: 'products.', 381: 'view', 382: 'contained', 383: \"Africa's\", 384: 'bodies,', 385: 'addition,', 386: 'delegations', 387: 'Annex', 388: 'Inventory/chart', 389: 'for', 390: 'formed', 391: 'addendum', 392: 'designed', 393: 'Declaratory', 394: 'subscribers', 395: 'subsidiary', 396: 'one-time', 397: 'Proceedings', 398: 'viewing;', 399: 'A', 400: 'constitute', 401: '(A/62/952),', 402: 'implemented', 403: 'overview', 404: 'integral', 405: 'advocacy', 406: 'findings', 407: 'comprise', 408: 'material,', 409: 'numerous', 410: 'index', 411: '(www.un.org/Depts/dhl/resguide/),', 412: 'documents', 413: 'While', 414: 'These', 415: 'e-mail', 416: 'News', 417: 'Our', 418: 'network', 419: 'comprehensive', 420: '(for', 421: 'similar', 422: 'discussions', 423: 'with', 424: 'remaining', 425: 'Television', 426: 'departure', 427: 'edition', 428: 'opportunities', 429: 'mostly', 430: 'indicating', 431: 'Where', 432: 'others.', 433: 'uploaded', 434: 'community', 435: 'such', 436: 'Co-Chairs', 437: 'their', 438: 'by', 439: 'updating', 440: 'paragraph', 441: 'provided', 442: 'time', 443: 'staff,', 444: 'selection', 445: 'or', 446: 'peace', 447: 'serve', 448: 'support', 449: 'operative', 450: 'evaluation', 451: 'authoritative', 452: 'principal', 453: 'possible,', 454: 'legal', 455: 'minutes', 456: '(in', 457: 'offers', 458: 'used.', 459: 'weekly', 460: 'parts', 461: 'events', 462: 'discussion', 463: 'taken', 464: 'certain', 465: 'including', 466: 'through', 467: 'next', 468: 'non-governmental', 469: 'report', 470: 'nature', 471: 'symbol', 472: 'statements', 473: 'adopt', 474: 'request', 475: 'our', 476: 'daily', 477: 'available', 478: 'reports', 479: 'made', 480: 'one', 481: 'Working', 482: 'characterizes', 483: 'Public', 484: 'customary', 485: 'Department.', 486: 'II', 487: 'open', 488: 'those', 489: 'declarations', 490: 'more', 491: 'signal,', 492: 'website.', 493: 'Cyberschoolbus', 494: 'speeches', 495: 'delivery', 496: 'documentation', 497: 'Declaration', 498: 'resolution', 499: 'Explanatory', 500: 'scope', 501: 'since', 502: 'fulfil', 503: 'It', 504: 'commemoration', 505: 'promotes', 506: 'Portuguese', 507: 'partner', 508: 'role', 509: 'III', 510: 'could', 511: 'whose', 512: 'Dag', 513: 'provides', 514: 'circulated', 515: 'established', 516: 'Furthermore,', 517: 'Assembly;', 518: 'practice-', 519: 'management', 520: '(www.un.org/Depts/dhl/resguide/resins.htm);', 521: '62/276).', 522: 'detailed', 523: 'provisions', 524: 'Texts', 525: 'all:', 526: 'session,', 527: 'trafficking,', 528: 'Knowledge', 529: 'sixtieth', 530: 'adoption', 531: 'issued', 532: 'affiliated', 533: 'prominently', 534: 'kits', 535: 'significance', 536: 'also', 537: 'Offices', 538: 'letter', 539: 'May', 540: 'Addendum', 541: 'etc.', 542: 'photographers,', 543: 'have', 544: 'fifty-first', 545: 'it', 546: 'duplication,', 547: 'at', 548: '9', 549: 'it.', 550: 'many', 551: 'includes', 552: 'seeks', 553: \"Group's\", 554: 'dated', 555: 'Consequently,', 556: 'decided', 557: 'I', 558: 'before', 559: 'President,', 560: 'ongoing', 561: 'awareness', 562: 'briefings', 563: 'some', 564: 'Revitalization', 565: 'organizing', 566: 'new', 567: 'rules', 568: 'different', 569: 'Chairpersons.', 570: 'context,', 571: 'AIDS,', 572: 'character', 573: 'audio', 574: 'Contents', 575: 'definitive', 576: 'Swahili)', 577: 'programmes', 578: 'www.un.org/ga/ropga.shtml.', 579: 'provision,', 580: 'downloading;', 581: 'as', 582: 'Partnership', 583: 'that', 584: 'number', 585: 'million', 586: 'young', 587: 'enhance', 588: 'Headquarters', 589: 'students,', 590: 'session', 591: 'basis,', 592: 'Research', 593: 'makes', 594: 'publicize', 595: 'whether', 596: 'note', 597: 'voting', 598: 'solely', 599: 'will', 600: 'revitalization,', 601: 'terms', 602: 'approach', 603: 'no', 604: 'three', 605: 'distributors;', 606: 'achieved', 607: 'guided', 608: 'progress', 609: 'inventory/chart', 610: 'Hall', 611: 'Report', 612: '(http://unbisnet.un.org),', 613: 'words,', 614: 'documentation,', 615: 'action', 616: 'outputs', 617: '(reflecting', 618: 'Index', 619: 'Committee', 620: 'out', 621: '1948.', 622: 'references', 623: 'Development', 624: 'amended', 625: '2008,', 626: 'into', 627: 'Ad', 628: 'UNBISnet', 629: 'indicates', 630: 'UN', 631: 'revitalization', 632: 'results', 633: 'attend', 634: 'its', 635: 'Group', 636: 'September', 637: 'press', 638: 'catalogue', 639: 'information', 640: 'scanned', 641: 'resolutions,', 642: 'live', 643: 'thirty-sixth', 644: '(establishing', 645: 'providing', 646: 'not', 647: 'is', 648: 'both', 649: 'actions.', 650: 'All', 651: 'structure', 652: 'six', 653: 'found', 654: 'Universal', 655: 'printed', 656: '15', 657: 'Committees.', 658: 'campaigns', 659: 'be', 660: 'deferring', 661: 'in', 662: 'people.', 663: 'Missions,', 664: 'facets.', 665: 'intended', 666: 'III:', 667: 'needed.', 668: 'On', 669: 'plenary', 670: 'interviews', 671: 'tool', 672: 'deliberations', 673: 'working', 674: 'rights', 675: 'President', 676: 'starting', 677: 'As', 678: 'Centres,'}\n"
     ]
    }
   ],
   "source": [
    "print(num2wordX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'avoid'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num2wordX[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_inputs = tf.placeholder(tf.int32, (None, None), \"encoder_inputs\")\n",
    "encoder_inputs_length = tf.placeholder(tf.int32, (None, ), \"encoder_inputs_length\")\n",
    "decoder_inputs = tf.placeholder(tf.int32, (None, None), \"decoder_inputs\")\n",
    "decoder_targets = tf.placeholder(tf.int32, (None, None), \"decoder_targets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_embedding = tf.Variable(tf.random_uniform((vocab_size, embed_size), -1.0, 1.0), name=\"input_embedding\")\n",
    "output_embedding = tf.Variable(tf.random_uniform((len(word2numY),embed_size), -1.0, 1.0), name=\"output_embedding\")\n",
    "embedded_input = tf.nn.embedding_lookup(input_embedding, encoder_inputs)\n",
    "embedded_output = tf.nn.embedding_lookup(output_embedding, decoder_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder: Bidirectional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "((enc_fw_outputs, enc_bw_outputs),\n",
    "(enc_fw_last_state, enc_bw_last_state)) = (tf.nn.bidirectional_dynamic_rnn\n",
    "                                            (cell_fw=encoder_cell,\n",
    "                                             cell_bw=encoder_cell,\n",
    "                                             inputs=embedded_input,\n",
    "                                             sequence_length=encoder_inputs_length,\n",
    "                                             dtype=tf.float32, time_major=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_outputs = tf.concat((enc_fw_outputs, enc_bw_outputs), 2)\n",
    "enc_last_state_c = tf.concat((enc_fw_last_state.c, enc_bw_last_state.c),1)\n",
    "enc_last_state_h = tf.concat((enc_fw_last_state.h, enc_bw_last_state.h),1)\n",
    "encoder_last_state = LSTMStateTuple(\n",
    "    c=enc_last_state_c,\n",
    "    h=enc_last_state_h\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder: Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder_cell = LSTMCell(lstm_size_decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_max_time, batch_size = tf.unstack(tf.shape(encoder_inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder_lengths = encoder_inputs_length + 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#manually specifying since we are going to implement attention details for the decoder in a sec\n",
    "#weights\n",
    "W = tf.Variable(tf.random_uniform([lstm_size_decoder, vocab_size], -1, 1), dtype=tf.float32)\n",
    "#bias\n",
    "b = tf.Variable(tf.zeros([vocab_size]), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert EOS == 1 and PAD == 0\n",
    "\n",
    "eos_time_slice = tf.ones([batch_size], dtype=tf.int32, name='EOS')\n",
    "pad_time_slice = tf.zeros([batch_size], dtype=tf.int32, name='PAD')\n",
    "\n",
    "#retrieves rows of the params tensor. The behavior is similar to using indexing with arrays in numpy\n",
    "eos_step_embedded = tf.nn.embedding_lookup(input_embedding, eos_time_slice)\n",
    "pad_step_embedded = tf.nn.embedding_lookup(input_embedding, pad_time_slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loop_fn_initial():\n",
    "    initial_elements_finished = (0 >= decoder_lengths)  # all False at the initial step\n",
    "    #end of sentence\n",
    "    initial_input = eos_step_embedded\n",
    "    #last time steps cell state\n",
    "    initial_cell_state = encoder_last_state\n",
    "    #none\n",
    "    initial_cell_output = None\n",
    "    #none\n",
    "    initial_loop_state = GO  # we don't need to pass any additional information\n",
    "    return (initial_elements_finished,\n",
    "            initial_input,\n",
    "            initial_cell_state,\n",
    "            initial_cell_output,\n",
    "            initial_loop_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#attention mechanism --choose which previously generated token to pass as input in the next timestep\n",
    "def loop_fn_transition(time, previous_output, previous_state, previous_loop_state):\n",
    "\n",
    "    \n",
    "    def get_next_input():\n",
    "        #dot product between previous ouput and weights, then + biases\n",
    "        output_logits = tf.add(tf.matmul(previous_output, W), b)\n",
    "        #Logits simply means that the function operates on the unscaled output of \n",
    "        #earlier layers and that the relative scale to understand the units is linear. \n",
    "        #It means, in particular, the sum of the inputs may not equal 1, that the values are not probabilities \n",
    "        #(you might have an input of 5).\n",
    "        #prediction value at current time step\n",
    "        \n",
    "        #Returns the index with the largest value across axes of a tensor.\n",
    "        prediction = tf.argmax(output_logits, axis=1)\n",
    "        #embed prediction for the next input\n",
    "        next_input = tf.nn.embedding_lookup(input_embedding, prediction)\n",
    "        return next_input\n",
    "    \n",
    "    \n",
    "    elements_finished = (time >= decoder_lengths) # this operation produces boolean tensor of [batch_size]\n",
    "                                                  # defining if corresponding sequence has ended\n",
    "\n",
    "    \n",
    "    \n",
    "    #Computes the \"logical and\" of elements across dimensions of a tensor.\n",
    "    finished = tf.reduce_all(elements_finished) # -> boolean scalar\n",
    "    #Return either fn1() or fn2() based on the boolean predicate pred.\n",
    "    input = tf.cond(finished, lambda: pad_step_embedded, get_next_input)\n",
    "    \n",
    "    #set previous to current\n",
    "    state = previous_state\n",
    "    output = previous_output + embedded_output[-1]\n",
    "    loop_state = None\n",
    "\n",
    "    return (elements_finished, \n",
    "            input,\n",
    "            state,\n",
    "            output,\n",
    "            loop_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loop_fn(time, previous_output, previous_state, previous_loop_state):\n",
    "    if previous_state is None:    # time == 0\n",
    "        assert previous_output is None and previous_state is None\n",
    "        return loop_fn_initial()\n",
    "    else:\n",
    "        return loop_fn_transition(time, previous_output, previous_state, previous_loop_state)\n",
    "\n",
    "#Creates an RNN specified by RNNCell cell and loop function loop_fn.\n",
    "#This function is a more primitive version of dynamic_rnn that provides more direct access to the \n",
    "#inputs each iteration. It also provides more control over when to start and finish reading the sequence, \n",
    "#and what to emit for the output.\n",
    "#ta = tensor array\n",
    "decoder_outputs_ta, decoder_last_state, decoder_loop_state = tf.nn.raw_rnn(decoder_cell, loop_fn)\n",
    "decoder_outputs = decoder_outputs_ta.stack()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'TensorArrayStack/TensorArrayGatherV3:0' shape=(?, ?, 256) dtype=float32>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#to convert output to human readable prediction\n",
    "#we will reshape output tensor\n",
    "\n",
    "#Unpacks the given dimension of a rank-R tensor into rank-(R-1) tensors.\n",
    "#reduces dimensionality\n",
    "decoder_max_steps, decoder_batch_size, decoder_dim = tf.unstack(tf.shape(decoder_outputs))\n",
    "#flettened output tensor\n",
    "decoder_outputs_flat = tf.reshape(decoder_outputs, (-1, decoder_dim))\n",
    "#pass flattened tensor through decoder\n",
    "decoder_logits_flat = tf.add(tf.matmul(decoder_outputs_flat, W), b)\n",
    "\n",
    "#prediction vals\n",
    "decoder_logits = tf.reshape(decoder_logits_flat, (decoder_max_steps, decoder_batch_size, vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#final prediction\n",
    "decoder_prediction = tf.argmax(decoder_logits, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#cross entropy loss\n",
    "#one hot encode the target values so we don't rank just differentiate\n",
    "stepwise_cross_entropy = tf.nn.softmax_cross_entropy_with_logits(\n",
    "    labels=tf.one_hot(decoder_targets, depth=vocab_size, dtype=tf.float32),\n",
    "    logits=decoder_logits,\n",
    ")\n",
    "\n",
    "#loss function\n",
    "loss = tf.reduce_mean(stepwise_cross_entropy)\n",
    "#train it \n",
    "train_op = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def next_feed():\n",
    "    batch = x[:300]\n",
    "    batch_y = y[:300]\n",
    "    encoder_inputs_, encoder_input_lengths_ = helpers.batch(batch)\n",
    "    decoder_inputs_, _ = helpers.batch(\n",
    "        [[GO] + (sequence) + [EOS] for sequence in batch_y]\n",
    "    )\n",
    "    decoder_targets_, _ = helpers.batch(\n",
    "        [(sequence) + [EOS] + [PAD] for sequence in batch_y]\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        encoder_inputs: encoder_inputs_,\n",
    "        encoder_inputs_length: encoder_input_lengths_,\n",
    "        decoder_inputs: decoder_inputs_,\n",
    "        decoder_targets: decoder_targets_,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def next_feed_test():\n",
    "    batch_x_test = x[400:]\n",
    "    dec_input = np.zeros((len(batch_x_test), 1)) + 0\n",
    "    batch_y_test = y[400:]\n",
    "    encoder_inputs_, encoder_input_lengths_ = helpers.batch(batch_x_test)\n",
    "#     decoder_inputs_, _ = helpers.batch(\n",
    "#         [[GO] + (sequence) + [EOS] + [PAD] * 3 for sequence in batch_y_test]\n",
    "#     )\n",
    "#     decoder_targets_, _ = helpers.batch(\n",
    "#         [(sequence) + [EOS] + [PAD] * 4 for sequence in batch_y]\n",
    "#     )\n",
    "    return {\n",
    "        encoder_inputs: encoder_inputs_,\n",
    "        encoder_inputs_length: encoder_input_lengths_,\n",
    "        decoder_inputs: dec_input,\n",
    "    }, batch_x_test, batch_y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_track = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py:107: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    }
   ],
   "source": [
    "save_every = 50\n",
    "save_dir = 'data/'\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.initialize_all_variables())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================EPOCH   :   0 =============================\n",
      "batch 0/1001\n",
      "#####=====batch loss  :   9.484\n",
      "  sample 1:\n",
      "    input     > [  3 590   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0]\n",
      "    prediction     > [189 189 189 189 189 189 189 189 189 189 189 189 189 189 189 281 189 189\n",
      " 189 189 189 189 189 189   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      "  sample 2:\n",
      "    input     > [ 68 304 235   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0]\n",
      "    prediction     > [189 189 189 189 189 189 189 189 189 189 189 281 281 281 281 281 189 189\n",
      " 189 189 189 189 189 189 189   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      "  sample 3:\n",
      "    input     > [564 169 233  62 169 233 151 103   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0]\n",
      "    prediction     > [611 189 189 560 560 189 189 189 189 189 560 281 189 189 189 189 189 189\n",
      " 189 189 189 189 189 189 189 189 189 189 189 189   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      "#####=====training accuracy  :  0.916\n",
      "=============================EPOCH   :   1 =============================\n",
      "batch 50/1001\n",
      "#####=====batch loss  :   5.654\n",
      "  sample 1:\n",
      "    input     > [  3 590   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0]\n",
      "    prediction     > [633   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      "  sample 2:\n",
      "    input     > [ 68 304 235   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0]\n",
      "    prediction     > [449 656   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      "  sample 3:\n",
      "    input     > [564 169 233  62 169 233 151 103   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0]\n",
      "    prediction     > [426 506   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      "#####=====training accuracy  :  0.959\n"
     ]
    }
   ],
   "source": [
    "max_batches = 1001\n",
    "batches_in_epoch = 50\n",
    "num_batch_save = 50\n",
    "\n",
    "for batch in range(max_batches):\n",
    "    fd = next_feed()\n",
    "   \n",
    "    _, batch_loss, batch_logits = sess.run([train_op, loss, decoder_logits], fd)\n",
    "    if batch == 0 or batch % batches_in_epoch == 0:\n",
    "        Epoch = batch // batches_in_epoch\n",
    "        print('=============================EPOCH   :{:>4} ============================='.format(Epoch))\n",
    "        print('batch {}/{}'.format(batch, max_batches))\n",
    "        print('#####=====batch loss  :  {:>6.3f}'.format(batch_loss))\n",
    "        predict_ = sess.run(decoder_prediction, fd)\n",
    "        \n",
    "#      loss_track.append(batch_loss)\n",
    "# #     print(batch_loss)\n",
    "\n",
    "#     if batch == 0 or batch % batches_in_epoch == 0:\n",
    "#         print('batch {}'.format(batch))\n",
    "#         print('  minibatch loss: {}'.format(sess.run(loss, fd)))\n",
    "        \n",
    "#         save progress every 10000 iterations\n",
    "        for i, (inp, pred) in enumerate(zip(fd[encoder_inputs].T, predict_.T)):\n",
    "            print('  sample {}:'.format(i + 1))\n",
    "            print('    input     > {}'.format(inp))\n",
    "            print('    prediction     > {}'.format(pred))\n",
    "     \n",
    "\n",
    "            \n",
    "#             result_en = []\n",
    "#             for i in range(len(inp)):\n",
    "#                 temp_en = num2wordX[inp[i]]\n",
    "#                 result_en.append(temp_en)\n",
    "#             #print(result_en)\n",
    "            \n",
    "#             result_fr =[]\n",
    "#             for i in range(len(pred)):\n",
    "#                 temp_fr = num2wordY[pred[i]]\n",
    "#                 result_fr.append(temp_fr)\n",
    "#             print('input: {} ========================>\\nprediction: {}'.format(result_en,result_fr))\n",
    "            if i >= 2:\n",
    "                break\n",
    "        accuracy = np.mean(batch_logits.argmax(axis=-1)==predict_)\n",
    "        print('#####=====training accuracy  : {:>6.3f}'.format(accuracy))\n",
    "    \n",
    "#         print(batch_logits.argmax(axis=-1))\n",
    "#         print(predict_)\n",
    "#         print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####==== Test Code\n",
    "\n",
    "_, source_batch, target_batch = next_feed_test()\n",
    "\n",
    "dec_input = np.zeros((len(source_batch), 1)) + 0\n",
    "#print(dec_input)\n",
    "for i in range(len(num2wordY)):\n",
    "    fd, _, _ = next_feed_test()\n",
    "    batch_logits = sess.run([decoder_logits], fd)\n",
    "    R = np.array(batch_logits)\n",
    "    print(R[:,-1])\n",
    "    prediction = R.argmax(axis=-1)\n",
    "    print(prediction)\n",
    "    dec_input = np.hstack([dec_input, prediction[None,None]])\n",
    "    #print(dec_input)\n",
    "    #print(target_batch)\n",
    "#     if batch == 0 or batch % batches_in_epoch == 0:\n",
    "#         #print(batch_logits)\n",
    "#         print('batch {}'.format(batch))\n",
    "#         print(batch_loss)\n",
    "#         predict_ = sess.run(decoder_prediction, fd)\n",
    "        \n",
    "# #      loss_track.append(batch_loss)\n",
    "# # #     print(batch_loss)\n",
    "\n",
    "# #     if batch == 0 or batch % batches_in_epoch == 0:\n",
    "# #         print('batch {}'.format(batch))\n",
    "# #         print('  minibatch loss: {}'.format(sess.run(loss, fd)))\n",
    "        \n",
    "# #         save progress every 10000 iterations\n",
    "#         for i, (inp, pred) in enumerate(zip(fd[encoder_inputs].T, predict_.T)):\n",
    "#             print('  sample {}:'.format(i + 1))\n",
    "#             print('    input     > {}'.format(inp))\n",
    "#             print('    prediction     > {}'.format(pred))\n",
    "#             if i >= 2:\n",
    "#                 break\n",
    "accuracy = np.mean(dec_input == target_batch)\n",
    "print(accuracy)\n",
    "\n",
    "#         print(batch_logits.argmax(axis=-1))\n",
    "#         print(predict_)\n",
    "#         print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss_track)\n",
    "print('loss {:.4f} after {} examples (batch_size={})'.format(loss_track[-1], len(loss_track)*batch_size, batch_size))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
