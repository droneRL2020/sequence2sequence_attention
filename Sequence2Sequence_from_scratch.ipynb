{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.ops.rnn_cell import LSTMCell, LSTMStateTuple\n",
    "import helpers\n",
    "import os\n",
    "#LSTMStateTuple(c,h)에서 c는 hidden state h는 output\n",
    "\n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lstm_size_encoder = 128\n",
    "lstm_size_decoder = 256\n",
    "vocab_size = 679 #띄어쓰기도 하나의 word야?\n",
    "embed_size = 100# Document Vector로 Input된 총 문장수고 각 Vocab이 몇번 나왔는지 표기(?)\n",
    "#max_length = 5 \n",
    "\n",
    "\n",
    "#batch_size = 32\n",
    "encoder_cell = LSTMCell(lstm_size_encoder)\n",
    "decoder_cell = LSTMCell(lstm_size_decoder)\n",
    "PAD = 0\n",
    "EOS = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings: Used int type embedding lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# inputs = tf.placeholder(tf.int32, (None, max_length), \"inputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input_embedding = tf.Variable(tf.random_uniform([vocab_size, embed_size], -1.0, 1.0), name=\"embedding\")\n",
    "# # x = tf.nn.embedding_lookup(input_embedding, inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lstm_enc = tf.contrib.rnn.BasicLSTMCell(lstm_size_encoder)\n",
    "# _, last_state = tf.nn.dynamic_rnn(lstm_enc, inputs=x, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sess.run(tf.global_variables_initializer())\n",
    "# last_state_val = sess.run([last_state],\n",
    "#                           feed_dict={\n",
    "#                               inputs: np.random.randint(0, 8, (batch_size, max_length))\n",
    "#                           })\n",
    "# print(last_state_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = \"eng_fre_dataset/multiUN.en/un/text/en-fr/2009\"\n",
    "#save_dir = \"eng_fre_dataset/multiUN.en/un/text/en-fr/2009\"\n",
    "input_file_en = os.path.join(data_dir, \"A_62_952_ADD1_en.snt\")\n",
    "lines_en = []\n",
    "with open(input_file_en, \"r\", encoding=\"utf-8\") as f_en:\n",
    "    for line in f_en.readlines():\n",
    "        line = line.replace('\\n','')\n",
    "        if not line == '':\n",
    "            lines_en.append(line)\n",
    "        \n",
    "print(lines_en[-2])\n",
    "#print((\"Text loaded from '%s'\") % (input_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = \"eng_fre_dataset/multiUN.en/un/text/en-fr/2009\"\n",
    "#save_dir = \"eng_fre_dataset/multiUN.en/un/text/en-fr/2009\"\n",
    "input_file_fr = os.path.join(data_dir, \"A_62_952_ADD1_fr.snt\")\n",
    "lines_fr = []\n",
    "with open(input_file_fr, \"r\", encoding=\"utf-8\") as f_fr:\n",
    "    for line in f_fr.readlines():\n",
    "        line = line.replace('\\n','')\n",
    "        if not line == '':\n",
    "            lines_fr.append(line)\n",
    "        \n",
    "print(lines_fr[-2])\n",
    "#print((\"Text loaded from '%s'\") % (input_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(lines_en), len(lines_fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_data = []\n",
    "for i in range(len(lines_en)):\n",
    "    word_data.append((lines_en[i],lines_fr[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# word_data = [\n",
    "#     ('bye world good', 'thank you word'),\n",
    "#     ('sam gyup sal', 'ha ha'),\n",
    "#     ('bye world hi hi hi', 'Goodyhi')\n",
    "# ] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = [x for x, y in word_data]\n",
    "y = [y for x, y in word_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_list = []\n",
    "for i in range(len(x)):\n",
    "    x_text = x[i].split()\n",
    "    x_list.append(x_text)\n",
    "for i in range(1, len(x_list)):\n",
    "    x_list[i] = set(x_list[i-1]).union(set(x_list[i]))\n",
    "    x_words_set = x_list[len(x_list)-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_list = []\n",
    "for i in range(len(y)):\n",
    "    y_text = y[i].split()\n",
    "    y_list.append(y_text)\n",
    "for i in range(1, len(y_list)):\n",
    "    y_list[i] = set(y_list[i-1]).union(set(y_list[i]))\n",
    "    y_words_set = y_list[len(y_list)-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word2numX = dict(zip(x_words_set, range(len(x_words_set))))\n",
    "word2numY = dict(zip(y_words_set, range(len(y_words_set))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num2wordX = dict(zip(word2numX.values(), word2numX.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# max_len 뽑음\n",
    "numWordsList = []\n",
    "for word in x:\n",
    "    Words = word.split(' ')\n",
    "    num = len(Words)\n",
    "    numWordsList.append(num) \n",
    "max_len = max(numWordsList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "step1_X = [\n",
    "    word.split() for word in x\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "second_list = []\n",
    "for i in range(len(step1_X)):\n",
    "    first_list = []\n",
    "    for j in range(len(step1_X[i])):\n",
    "        k = word2numX[step1_X[i][j]]\n",
    "        first_list.append(k)\n",
    "        padded_list = first_list\n",
    "    second_list.append(padded_list)\n",
    "x = second_list\n",
    "x = np.array(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num2wordY = dict(zip(word2numY.values(), word2numY.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "step1_Y = [\n",
    "    word.split() for word in y\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "second_list = []\n",
    "for i in range(len(step1_Y)):\n",
    "    first_list = []\n",
    "    for j in range(len(step1_Y[i])):\n",
    "        k = word2numY[step1_Y[i][j]]\n",
    "        first_list.append(k)\n",
    "        padded_list = first_list\n",
    "    second_list.append(padded_list)\n",
    "y = second_list\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(len(word2numX))\n",
    "print(len(word2numY))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(num2wordX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num2wordX[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder: Bidirectional LSTM Cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_inputs = tf.placeholder(tf.int32, (None, None), \"encoder_inputs\")\n",
    "encoder_inputs_length = tf.placeholder(tf.int32, (None, ), \"encoder_inputs_length\")\n",
    "decoder_targets = tf.placeholder(tf.int32, (None, None), \"decoder_targets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_embedding = tf.Variable(tf.random_uniform((vocab_size, embed_size), -1.0, 1.0), name=\"embedding\")\n",
    "embedded_input = tf.nn.embedding_lookup(input_embedding, encoder_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "((enc_fw_outputs, enc_bw_outputs),\n",
    "(enc_fw_last_state, enc_bw_last_state)) = (tf.nn.bidirectional_dynamic_rnn\n",
    "                                            (cell_fw=encoder_cell,\n",
    "                                             cell_bw=encoder_cell,\n",
    "                                             inputs=embedded_input,\n",
    "                                             sequence_length=encoder_inputs_length,\n",
    "                                             dtype=tf.float32, time_major=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_outputs = tf.concat((enc_fw_outputs, enc_bw_outputs), 2)\n",
    "enc_last_state_c = tf.concat((enc_fw_last_state.c, enc_bw_last_state.c),1)\n",
    "enc_last_state_h = tf.concat((enc_fw_last_state.h, enc_bw_last_state.h),1)\n",
    "encoder_last_state = LSTMStateTuple(\n",
    "    c=enc_last_state_c,\n",
    "    h=enc_last_state_h\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder: Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder_cell = LSTMCell(lstm_size_decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_max_time, batch_size = tf.unstack(tf.shape(encoder_inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder_lengths = encoder_inputs_length + 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#manually specifying since we are going to implement attention details for the decoder in a sec\n",
    "#weights\n",
    "W = tf.Variable(tf.random_uniform([lstm_size_decoder, vocab_size], -1, 1), dtype=tf.float32)\n",
    "#bias\n",
    "b = tf.Variable(tf.zeros([vocab_size]), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert EOS == 1 and PAD == 0\n",
    "\n",
    "eos_time_slice = tf.ones([batch_size], dtype=tf.int32, name='EOS')\n",
    "pad_time_slice = tf.zeros([batch_size], dtype=tf.int32, name='PAD')\n",
    "\n",
    "#retrieves rows of the params tensor. The behavior is similar to using indexing with arrays in numpy\n",
    "eos_step_embedded = tf.nn.embedding_lookup(input_embedding, eos_time_slice)\n",
    "pad_step_embedded = tf.nn.embedding_lookup(input_embedding, pad_time_slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loop_fn_initial():\n",
    "    initial_elements_finished = (0 >= decoder_lengths)  # all False at the initial step\n",
    "    #end of sentence\n",
    "    initial_input = eos_step_embedded\n",
    "    #last time steps cell state\n",
    "    initial_cell_state = encoder_last_state\n",
    "    #none\n",
    "    initial_cell_output = None\n",
    "    #none\n",
    "    initial_loop_state = None  # we don't need to pass any additional information\n",
    "    return (initial_elements_finished,\n",
    "            initial_input,\n",
    "            initial_cell_state,\n",
    "            initial_cell_output,\n",
    "            initial_loop_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#attention mechanism --choose which previously generated token to pass as input in the next timestep\n",
    "def loop_fn_transition(time, previous_output, previous_state, previous_loop_state):\n",
    "\n",
    "    \n",
    "    def get_next_input():\n",
    "        #dot product between previous ouput and weights, then + biases\n",
    "        output_logits = tf.add(tf.matmul(previous_output, W), b)\n",
    "        #Logits simply means that the function operates on the unscaled output of \n",
    "        #earlier layers and that the relative scale to understand the units is linear. \n",
    "        #It means, in particular, the sum of the inputs may not equal 1, that the values are not probabilities \n",
    "        #(you might have an input of 5).\n",
    "        #prediction value at current time step\n",
    "        \n",
    "        #Returns the index with the largest value across axes of a tensor.\n",
    "        prediction = tf.argmax(output_logits, axis=1)\n",
    "        #embed prediction for the next input\n",
    "        next_input = tf.nn.embedding_lookup(input_embedding, prediction)\n",
    "        return next_input\n",
    "    \n",
    "    \n",
    "    elements_finished = (time >= decoder_lengths) # this operation produces boolean tensor of [batch_size]\n",
    "                                                  # defining if corresponding sequence has ended\n",
    "\n",
    "    \n",
    "    \n",
    "    #Computes the \"logical and\" of elements across dimensions of a tensor.\n",
    "    finished = tf.reduce_all(elements_finished) # -> boolean scalar\n",
    "    #Return either fn1() or fn2() based on the boolean predicate pred.\n",
    "    input = tf.cond(finished, lambda: pad_step_embedded, get_next_input)\n",
    "    \n",
    "    #set previous to current\n",
    "    state = previous_state\n",
    "    output = previous_output\n",
    "    loop_state = None\n",
    "\n",
    "    return (elements_finished, \n",
    "            input,\n",
    "            state,\n",
    "            output,\n",
    "            loop_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loop_fn(time, previous_output, previous_state, previous_loop_state):\n",
    "    if previous_state is None:    # time == 0\n",
    "        assert previous_output is None and previous_state is None\n",
    "        return loop_fn_initial()\n",
    "    else:\n",
    "        return loop_fn_transition(time, previous_output, previous_state, previous_loop_state)\n",
    "\n",
    "#Creates an RNN specified by RNNCell cell and loop function loop_fn.\n",
    "#This function is a more primitive version of dynamic_rnn that provides more direct access to the \n",
    "#inputs each iteration. It also provides more control over when to start and finish reading the sequence, \n",
    "#and what to emit for the output.\n",
    "#ta = tensor array\n",
    "decoder_outputs_ta, decoder_last_state, _ = tf.nn.raw_rnn(decoder_cell, loop_fn)\n",
    "decoder_outputs = decoder_outputs_ta.stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#to convert output to human readable prediction\n",
    "#we will reshape output tensor\n",
    "\n",
    "#Unpacks the given dimension of a rank-R tensor into rank-(R-1) tensors.\n",
    "#reduces dimensionality\n",
    "decoder_max_steps, decoder_batch_size, decoder_dim = tf.unstack(tf.shape(decoder_outputs))\n",
    "#flettened output tensor\n",
    "decoder_outputs_flat = tf.reshape(decoder_outputs, (-1, decoder_dim))\n",
    "#pass flattened tensor through decoder\n",
    "decoder_logits_flat = tf.add(tf.matmul(decoder_outputs_flat, W), b)\n",
    "#prediction vals\n",
    "decoder_logits = tf.reshape(decoder_logits_flat, (decoder_max_steps, decoder_batch_size, vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#final prediction\n",
    "decoder_prediction = tf.argmax(decoder_logits, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#cross entropy loss\n",
    "#one hot encode the target values so we don't rank just differentiate\n",
    "stepwise_cross_entropy = tf.nn.softmax_cross_entropy_with_logits(\n",
    "    labels=tf.one_hot(decoder_targets, depth=vocab_size, dtype=tf.float32),\n",
    "    logits=decoder_logits,\n",
    ")\n",
    "\n",
    "#loss function\n",
    "loss = tf.reduce_mean(stepwise_cross_entropy)\n",
    "#train it \n",
    "train_op = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def next_feed():\n",
    "    batch = x\n",
    "    batch_y = y\n",
    "    encoder_inputs_, encoder_input_lengths_ = helpers.batch(batch)\n",
    "    decoder_targets_, _ = helpers.batch(\n",
    "        [(sequence) + [EOS] + [PAD] for sequence in batch_y]\n",
    "    )\n",
    "    return {\n",
    "        encoder_inputs: encoder_inputs_,\n",
    "        encoder_inputs_length: encoder_input_lengths_,\n",
    "        decoder_targets: decoder_targets_,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_track = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_batches = 301\n",
    "batches_in_epoch = 100\n",
    "\n",
    "\n",
    "for batch in range(max_batches):\n",
    "    fd = next_feed()\n",
    "    _, l = sess.run([train_op, loss], fd)\n",
    "    loss_track.append(l)\n",
    "\n",
    "    if batch == 0 or batch % batches_in_epoch == 0:\n",
    "        print('batch {}'.format(batch))\n",
    "        print('  minibatch loss: {}'.format(sess.run(loss, fd)))\n",
    "        predict_ = sess.run(decoder_prediction, fd)\n",
    "        for i, (inp, pred) in enumerate(zip(fd[encoder_inputs].T, predict_.T)):\n",
    "            print('  sample {}:'.format(i + 1))\n",
    "            print('    input     > {}'.format(len(inp)))\n",
    "            print('    prediction     > {}'.format(len(pred)))\n",
    "#             result_en = []\n",
    "#             for i in range(len(inp)):\n",
    "#                 temp_en = num2wordX[inp[i]]\n",
    "#                 result_en.append(temp_en)\n",
    "#             #print(result_en)\n",
    "            \n",
    "#             result_fr =[]\n",
    "#             for i in range(len(pred)):\n",
    "#                 temp_fr = num2wordY[pred[i]]\n",
    "#                 result_fr.append(temp_fr)\n",
    "#             print('input: {} ========================>\\nprediction: {}'.format(result_en,result_fr))\n",
    "            if i >= 10:\n",
    "                break\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ('bye world good', 'thank you word') ==>  (3 2 0), (0 2 1)\n",
    "# ('sam gyup sal', 'ha ha'),          ===>  (5 1 6), (4 4 )\n",
    "# ('bye world hi hi hi', 'Goodyhi') =====>  (3 2 4 4 4 ), (3)\n",
    "    \n",
    "print(word2numX)\n",
    "#print(len(word2numX))\n",
    "print(word2numY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
